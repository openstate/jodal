# Scraper for the OCCRP web site.
# The goal is not to download all HTML, but only PDFs & other documents
# linked from the page as proof.
name: decentrale_regelgeving

# A title for display in the UI:
description: "Decentrale Regelgeving"
#delay: 2

pipeline:
  init:
    # This first stage will get the ball rolling with a seed URL.
    method: seed
    params:
      urls:
        - https://zoekdienst.overheid.nl/sru/Search?version=1.2&operation=searchRetrieve&x-connection=cvdr&startRecord=1&maximumRecords=10&query=keyword=""
    handle:
      pass: fetch
  fetch:
    # Download the seed page
    method: fetch
    params:
      http_rate_limit: 60
    handle:
      pass: crawl
  crawl:
    # Crawl the HTML of the page passed in to extract specific things.
    method: decentrale_regelgeving.xml:crawl_simple
    params:
      paging: true
    handle:
      # If the 'fetch' rule is invoked, re-trigger the fetch stage
      fetch: fetch
      # Otherwise, pass data on to the store stage
      pass: store
  store:
    # Store the crawled documents to a directory
    # method: aleph_emit
    method: directory
    params:
      path: /data/results
