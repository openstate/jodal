# Scraper for the OCCRP web site.
# The goal is not to download all HTML, but only PDFs & other documents
# linked from the page as proof.
name: decentrale_regelgeving_recent
#delay: 1

# A title for display in the UI:
description: "Decentrale Regelgeving"

pipeline:
  # This first stage will get the ball rolling with a seed URL.
  init:
    method: decentrale_regelgeving.xml:crawl_first
    params:
      #from: 2022-04-19
      #to: 2000-01-01
    handle:
      pass: fetch
  fetch:
    # Download the seed page
    method: fetch
    params:
      http_rate_limit: 60
      emit_errors: true
    handle:
      pass: refetch
  refetch:
    method: decentrale_regelgeving.xml:refetch
    handle:
      pass: crawl
  crawl:
    # Crawl the HTML of the page passed in to extract specific things.
    method: decentrale_regelgeving.xml:crawl_simple
    params:
      paging: true
    handle:
      # If the 'fetch' rule is invoked, re-trigger the fetch stage
      fetch: fetch
      # Otherwise, pass data on to the store stage
      pass: store
  store:
    # Store the crawled documents to a directory
    # method: aleph_emit
    method: directory
    params:
      path: /data/results
