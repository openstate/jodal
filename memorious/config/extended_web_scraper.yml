# Example scraper to demonstrate extending Memorious
name: quote_scraper
description: Quotes to scraper
# delay: 2
pipeline:
  init:
    # The first stage logs in and creates an HTTP session which is used for subsequent requests.
    method: example.quotes:login
    params:
      url: http://quotes.toscrape.com
      username: fred
      password: asdfasdf
    handle:
      pass: fetch
  fetch:
    # Download the page passed from the login stage.
    method: fetch
    params:
      http_rate_limit: 60
    handle:
      pass: crawl
  crawl:
    # Crawl the HTML of the page passed in to extract specific things.
    method: example.quotes:crawl
    handle:
      # If the 'fetch' rule is invoked, re-trigger the fetch stage
      fetch: fetch
      # If the 'cleanup' rule is invoked, delete the downloaded page from archive
      cleanup: cleanup
      # Otherwise, pass data on to the store stage
      pass: store
  store:
    # Use a database to store structured data (which is either SQLite or otherwise set with the MEMORIOUS_DATASTORE_URI environment variable).
    method: example.quotes:store
    params:
      table: example_quotes
  cleanup:
    method: cleanup_archive
aggregator:
  method: example.quotes:export
  params:
    table: example_quotes
    filename: all_quotes.json
